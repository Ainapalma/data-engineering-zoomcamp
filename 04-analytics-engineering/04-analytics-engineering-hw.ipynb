{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a01884",
   "metadata": {},
   "source": [
    "## Question 1: Understanding dbt model resolution\n",
    "\n",
    "Provided you've got the following sources.yaml\n",
    "\n",
    "\n",
    "```\n",
    "sources:\n",
    "  - name: raw_nyc_tripdata\n",
    "    database: \"{{ env_var('DBT_BIGQUERY_PROJECT', 'dtc_zoomcamp_2025') }}\"\n",
    "    schema:   \"{{ env_var('DBT_BIGQUERY_SOURCE_DATASET', 'raw_nyc_tripdata') }}\"\n",
    "    tables:\n",
    "      - name: ext_green_taxi\n",
    "      - name: ext_yellow_taxi\n",
    "```\n",
    "\n",
    "with the following env variables setup where dbt runs:\n",
    "\n",
    "```\n",
    "export DBT_BIGQUERY_PROJECT=myproject\n",
    "export DBT_BIGQUERY_DATASET=my_nyc_tripdata\n",
    "```\n",
    "\n",
    "What does this .sql model compile to?\n",
    "\n",
    "```\n",
    "select * \n",
    "from {{ source('raw_nyc_tripdata', 'ext_green_taxi' ) }}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a54ea",
   "metadata": {},
   "source": [
    "From docs:\n",
    "env_var accepts a second, optional argument for default value.\n",
    "This can be useful to avoid compilation errors when the environment variable isn't available.\n",
    "https://docs.getdbt.com/reference/dbt-jinja-functions/env_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e11b7",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "- select * from dtc_zoomcamp_2025.raw_nyc_tripdata.ext_green_taxi\n",
    "- select * from dtc_zoomcamp_2025.my_nyc_tripdata.ext_green_taxi\n",
    "- select * from myproject.raw_nyc_tripdata.ext_green_taxi\n",
    "- **select * from myproject.my_nyc_tripdata.ext_green_taxi**\n",
    "- select * from dtc_zoomcamp_2025.raw_nyc_tripdata.green_taxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f39da",
   "metadata": {},
   "source": [
    "### Question 2: dbt Variables & Dynamic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ab83b",
   "metadata": {},
   "source": [
    "Say you have to modify the following dbt_model (fct_recent_taxi_trips.sql) \n",
    "to enable Analytics Engineers to dynamically control the date range.\n",
    "\n",
    "- In development, you want to process only the last 7 days of trips\n",
    "- In production, you need to process the last 30 days for analytics\n",
    "\n",
    "```\n",
    "select *\n",
    "from {{ ref('fact_taxi_trips') }}\n",
    "where pickup_datetime >= CURRENT_DATE - INTERVAL '30' DAY\n",
    "```\n",
    "\n",
    "What would you change to accomplish that in a such way that command line arguments takes precedence over ENV_VARs, which takes precedence over DEFAULT value?\n",
    "\n",
    "- Add ORDER BY pickup_datetime DESC and LIMIT {{ var(\"days_back\", 30) }}\n",
    "- Update the WHERE clause to pickup_datetime >= CURRENT_DATE - INTERVAL '{{ var(\"days_back\", 30) }}' DAY\n",
    "- **Update the WHERE clause to pickup_datetime >= CURRENT_DATE - INTERVAL '{{ env_var(\"DAYS_BACK\", \"30\") }}' DAY**\n",
    "- Update the WHERE clause to pickup_datetime >= CURRENT_DATE - INTERVAL '{{ var(\"days_back\", env_var(\"DAYS_BACK\", \"30\")) }}' DAY\n",
    "- Update the WHERE clause to pickup_datetime >= CURRENT_DATE - INTERVAL '{{ env_var(\"DAYS_BACK\", var(\"days_back\", \"30\")) }}' DAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a35c49",
   "metadata": {},
   "source": [
    "### Question 3: dbt Data Lineage and Execution\n",
    "\n",
    "Considering the data lineage below and that taxi_zone_lookup is the only materialization build (from a .csv seed file):\n",
    "\n",
    "image\n",
    "\n",
    "Select the option that does NOT apply for materializing fct_taxi_monthly_zone_revenue:\n",
    "\n",
    "- dbt run\n",
    "- **dbt run --select +models/core/dim_taxi_trips.sql+ --target prod**\n",
    "- dbt run --select +models/core/fct_taxi_monthly_zone_revenue.sql\n",
    "- dbt run --select +models/core/\n",
    "- dbt run --select models/staging/+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80927b",
   "metadata": {},
   "source": [
    "### Question 4: dbt Macros and Jinja\n",
    "\n",
    "Consider you're dealing with sensitive data (e.g.: PII), that is only available to your team and very selected few individuals, in the raw layer of your DWH (e.g: a specific BigQuery dataset or PostgreSQL schema),\n",
    "\n",
    "- Among other things, you decide to obfuscate/masquerade that data through your staging models, and make it available in a different schema (a staging layer) for other Data/Analytics Engineers to explore\n",
    "- And optionally, yet another layer (service layer), where you'll build your dimension (dim_) and fact (fct_) tables (assuming the Star Schema dimensional modeling) for Dashboarding and for Tech Product Owners/Managers\n",
    "\n",
    "You decide to make a macro to wrap a logic around it:\n",
    "\n",
    "```\n",
    "{% macro resolve_schema_for(model_type) -%}\n",
    "\n",
    "    {%- set target_env_var = 'DBT_BIGQUERY_TARGET_DATASET'  -%}\n",
    "    {%- set stging_env_var = 'DBT_BIGQUERY_STAGING_DATASET' -%}\n",
    "\n",
    "    {%- if model_type == 'core' -%} {{- env_var(target_env_var) -}}\n",
    "    {%- else -%}                    {{- env_var(stging_env_var, env_var(target_env_var)) -}}\n",
    "    {%- endif -%}\n",
    "\n",
    "{%- endmacro %}\n",
    "```\n",
    "\n",
    "And use on your staging, dim_ and fact_ models as:\n",
    "\n",
    "```\n",
    "{{ config(\n",
    "    schema=resolve_schema_for('core'), \n",
    ") }}\n",
    "```\n",
    "\n",
    "That all being said, regarding macro above, select all statements that are true to the models using it:\n",
    "\n",
    "- **Setting a value for DBT_BIGQUERY_TARGET_DATASET env var is mandatory, or it'll fail to compile**\n",
    "- Setting a value for DBT_BIGQUERY_STAGING_DATASET env var is mandatory, or it'll fail to compile\n",
    "- **When using core, it materializes in the dataset defined in DBT_BIGQUERY_TARGET_DATASET**\n",
    "- When using stg, it materializes in the dataset defined in DBT_BIGQUERY_STAGING_DATASET, or defaults to DBT_BIGQUERY_TARGET_DATASET\n",
    "- **When using staging, it materializes in the dataset defined in DBT_BIGQUERY_STAGING_DATASET, or defaults to DBT_BIGQUERY_TARGET_DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8bd737",
   "metadata": {},
   "source": [
    "### Question 5: Taxi Quarterly Revenue Growth\n",
    "\n",
    "1. Create a new model fct_taxi_trips_quarterly_revenue.sql\n",
    "2. Compute the Quarterly Revenues for each year for based on total_amount\n",
    "3. Compute the Quarterly YoY (Year-over-Year) revenue growth\n",
    "\n",
    "e.g.: In 2020/Q1, Green Taxi had -12.34% revenue growth compared to 2019/Q1      \n",
    "e.g.: In 2020/Q4, Yellow Taxi had +34.56% revenue growth compared to 2019/Q4\n",
    "\n",
    "Considering the YoY Growth in 2020, which were the yearly quarters with the best (or less worse) and worst results for green, and yellow\n",
    "\n",
    "\n",
    "- green: {best: 2020/Q2, worst: 2020/Q1}, yellow: {best: 2020/Q2, worst: 2020/Q1}\n",
    "- green: {best: 2020/Q2, worst: 2020/Q1}, yellow: {best: 2020/Q3, worst: 2020/Q4}\n",
    "- green: {best: 2020/Q1, worst: 2020/Q2}, yellow: {best: 2020/Q2, worst: 2020/Q1}\n",
    "- **green: {best: 2020/Q1, worst: 2020/Q2}, yellow: {best: 2020/Q1, worst: 2020/Q2}**\n",
    "- green: {best: 2020/Q1, worst: 2020/Q2}, yellow: {best: 2020/Q3, worst: 2020/Q4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f437cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_type\tquarter\trevenue_2019\trevenue_2020\tyoy_growth\n",
    "Green\t1\t26440794\t11480846\t43.420957782130145\n",
    "Green\t2\t21498354\t1544036\t\t7.182112639879314\n",
    "Green\t3\t17651034\t2360836\t\t13.375057801146381\n",
    "Green\t4\t15680621\t2441470\t\t15.569982846980359\n",
    "Yellow\t1\t182730721\t144118780\t78.86948577190806\n",
    "Yellow\t2\t200299519\t15560726\t7.7687285909059014\n",
    "Yellow\t3\t186986402\t41404395\t22.142997863555873\n",
    "Yellow\t4\t191429606\t56283852\t29.401853337147859"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe925223",
   "metadata": {},
   "source": [
    "### Question 6: P97/P95/P90 Taxi Monthly Fare\n",
    "\n",
    "1. Create a new model fct_taxi_trips_monthly_fare_p95.sql\n",
    "2. Filter out invalid entries (fare_amount > 0, trip_distance > 0, and payment_type_description in ('Cash', 'Credit Card'))\n",
    "3. Compute the continous percentile of fare_amount partitioning by service_type, year and and month\n",
    "\n",
    "Now, what are the values of p97, p95, p90 for Green Taxi and Yellow Taxi, in April 2020?\n",
    "\n",
    "- green: {p97: 55.0, p95: 45.0, p90: 26.5}, yellow: {p97: 52.0, p95: 37.0, p90: 25.5}\n",
    "- **green: {p97: 55.0, p95: 45.0, p90: 26.5}, yellow: {p97: 31.5, p95: 25.5, p90: 19.0}**\n",
    "- green: {p97: 40.0, p95: 33.0, p90: 24.5}, yellow: {p97: 52.0, p95: 37.0, p90: 25.5}\n",
    "- green: {p97: 40.0, p95: 33.0, p90: 24.5}, yellow: {p97: 31.5, p95: 25.5, p90: 19.0}\n",
    "- green: {p97: 55.0, p95: 45.0, p90: 26.5}, yellow: {p97: 52.0, p95: 25.5, p90: 19.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# service_type\tp97\tp95\tp90\n",
    "# Yellow\t31.5\t25.5\t19.0\n",
    "# Green\t\t55.0\t45.0\t26.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca34108",
   "metadata": {},
   "source": [
    "### Question 7: Top #Nth longest P90 travel time Location for FHV\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "- Create a staging model for FHV Data (2019), and DO NOT add a deduplication step, just filter out the entries where where dispatching_base_num is not null\n",
    "- Create a core model for FHV Data (dim_fhv_trips.sql) joining with dim_zones. Similar to what has been done here\n",
    "- Add some new dimensions year (e.g.: 2019) and month (e.g.: 1, 2, ..., 12), based on pickup_datetime, to the core model to facilitate filtering for your queries\n",
    "\n",
    "Now...\n",
    "\n",
    "1. Create a new model fct_fhv_monthly_zone_traveltime_p90.sql\n",
    "2. For each record in dim_fhv_trips.sql, compute the timestamp_diff in seconds between dropoff_datetime and pickup_datetime - we'll call it trip_duration for this exercise\n",
    "3. Compute the continous p90 of trip_duration partitioning by year, month, pickup_location_id, and dropoff_location_id\n",
    "\n",
    "For the Trips that respectively started from Newark Airport, SoHo, and Yorkville East, in November 2019, what are dropoff_zones with the 2nd longest p90 trip_duration ?\n",
    "\n",
    "- **LaGuardia Airport, Chinatown, Garment District**\n",
    "- LaGuardia Airport, Park Slope, Clinton East\n",
    "- LaGuardia Airport, Saint Albans, Howard Beach\n",
    "- LaGuardia Airport, Rosedale, Bath Beach\n",
    "- LaGuardia Airport, Yorkville East, Greenpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "select\n",
    "    distinct \n",
    "    pickup_zone,\n",
    "    dropoff_zone\n",
    "from (\n",
    "  select\n",
    "    pickup_zone,\n",
    "    dropoff_zone,\n",
    "    trip_duration,\n",
    "    p90,\n",
    "    dense_rank() over (partition by pickup_zone order by p90 desc) as r\n",
    "  from `fct_fhv_monthly_zone_traveltime_p90` \n",
    "  where year=2019 and month=11 and pickup_zone in ('Newark Airport', 'SoHo', 'Yorkville East')\n",
    ") t\n",
    "where r=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_zone\t\tdropoff_zone\n",
    "Yorkville East\tGarment District\n",
    "SoHo\t\t\tChinatown\n",
    "Newark Airport\tLaGuardia Airport"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
